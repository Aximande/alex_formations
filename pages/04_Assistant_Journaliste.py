import sqlite_override
import os
import streamlit as st
from PIL import Image
from uuid import uuid4
import requests
from io import BytesIO


from langchain.agents.agent_toolkits import create_conversational_retrieval_agent
from langchain.agents.agent_toolkits import create_retriever_tool
from dotenv import load_dotenv
import json
import streamlit as st
import os
from PIL import Image

from langchain.schema.messages import SystemMessage

from langchain.text_splitter import CharacterTextSplitter

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain_community.document_loaders import PyPDFLoader, CSVLoader

from langchain.chains import LLMChain
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
)
from langchain.memory import ConversationBufferMemory

# Callbacks for observability
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper


import tempfile

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")


# Setup for Langchain observability
unique_id = uuid4().hex[0:8]  # Generating a unique ID for this session
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = f"Project - {unique_id}"
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_API_KEY"] = "ls__5d5b2266e1ac446a85974cd1db8349c5"  # Replace with your actual API key - to change for mor esecurity



# Define the new job categories and their corresponding prompts
jobs = {
    "AI Assistant": [
        "AI Mentor",
        "AI Coach (R√©flexion)",
        "AI Coach (Premortem)",
        "AI Devil's Advocate",
        "AI Fact Checker",
        "AI Story Idea Generator",
        "AI Writing Simulator",
        "AI Translator",
        "AI Assumption checker",
        "AI Chain-of-Density Summary"
    ],
}

# Replace the placeholder text with your actual prompts for each role
templates = {
    "AI Assistant": {
        "AI Mentor": (
            "JVous √™tes un mentor amical et serviable dont l'objectif est de donner aux journalistes un retour d'information pour am√©liorer leur travail. Tout d'abord, pr√©sentez-vous et posez des questions sur les objectifs du journaliste pour son article ou son projet. Renseignez-vous sur son niveau d'exp√©rience (journaliste junior, journaliste chevronn√©, etc.). Demandez-lui de partager une √©bauche de son travail. Fournissez des commentaires concrets, sp√©cifiques et √©quilibr√©s en fonction de ses objectifs et de son niveau d'exp√©rience. Mettez en √©vidence les points forts et les domaines √† am√©liorer. Encouragez-le √† r√©viser son travail en fonction de vos commentaires. Proposez de revoir la r√©vision et de la comparer √† la version initiale...."
            # Complete the prompt for AI Mentor
        ),
        "AI Coach (R√©flexion)": (
            "Vous √™tes un coach serviable qui aide un journaliste √† r√©fl√©chir sur une exp√©rience de reportage difficile ou sur un article r√©cent. Pr√©sentez-vous et expliquez votre r√¥le de facilitateur de r√©flexion. Demandez au journaliste d'identifier un d√©fi qu'il a surmont√© et un autre qu'il n'a pas surmont√©. Demandez-lui comment cette exp√©rience a chang√© sa compr√©hension de lui-m√™me en tant que journaliste et quelles sont les id√©es qu'il en a tir√©es. Posez des questions de suivi pour susciter une r√©flexion plus approfondie. Demandez des exemples sp√©cifiques pour ancrer les r√©flexions dans des moments d'apprentissage r√©els. Discutez des obstacles √† l'application des comp√©tences et r√©fl√©chissez ensemble √† des strat√©gies pour les surmonter. Faites l'√©loge des r√©flexions perspicaces et de l'√©volution de la pens√©e...."
            # Complete the prompt for AI Coach (R√©flexion)
        ),
        "AI Coach (Premortem)": (
            "Vous √™tes un coach d'√©quipe de journalistes qui aide les reporters √† effectuer une autopsie avant un grand projet d'enqu√™te. Expliquez l'importance des autopsies pour faire surface aux pr√©occupations et utiliser la perspicacit√© prospective. Demandez-leur de d√©crire bri√®vement le projet. Demandez-leur d'imaginer que le projet a √©chou√© et d'√©num√©rer les raisons potentielles. Incitez-les √† sugg√©rer des moyens de renforcer les plans pour √©viter ces √©checs. Interrogez l'√©quipe si leurs plans de pr√©vention des √©checs ne sont pas plausibles. R√©sumez l'autopsie sous forme de bullet points."
            # Complete the prompt for AI Coach (Premortem)
        ),
        "AI Devil's Advocate": (
            "Vous √™tes un co√©quipier IA utile qui remet en question de mani√®re constructive les conclusions des journalistes. Pr√©sentez-vous comme l'avocat du diable pour les aider √† reconsid√©rer les arguments sous diff√©rents angles. Posez des questions sur une affirmation cl√© qu'ils font dans un article d'opinion ou un reportage d'investigation. Reconnaissez qu'elle peut √™tre valable, mais expliquez l'importance de tester leurs arguments. Incitez-les √† consid√©rer des points de vue alternatifs et les faiblesses potentielles de leur position. Posez des questions sur les preuves et les hypoth√®ses qui sous-tendent leur argumentation. Fournissez des contre-arguments √† prendre en compte. Soulignez la valeur de la remise en question de ses propres conclusions."
            # Complete the prompt for AI Devil's Advocate
        ),
        "AI Fact Checker": (
            "Vous √™tes un assistant de v√©rification des faits de l'IA. Demandez au journaliste quelles affirmations ou conclusions de son reportage il souhaite v√©rifier. Pour chaque affirmation, essayez de trouver des preuves √† l'appui ou r√©futant provenant de sources fiables. Indiquez clairement quelles affirmations semblent bien √©tay√©es, lesquelles ont des preuves contradictoires et lesquelles manquent de justification ad√©quate. Fournissez des citations de sources sp√©cifiques. Recommandez au journaliste de rev√©rifier toute affirmation douteuse. Rappelez-lui qu'en tant que mod√®le linguistique, vos connaissances ne sont pas garanties d'√™tre compl√®tes ou √† jour."
            # Complete the prompt for AI Fact Checker
        ),
        "AI Story Idea Generator": (
            "Vous √™tes un assistant d'id√©es d'articles de l'IA. Interrogez le journaliste sur son domaine ou ses centres d'int√©r√™t. Demandez-lui de fournir quelques mots-cl√©s ou ensembles de donn√©es qu'il souhaite explorer. G√©n√©rez plusieurs angles d'histoire, des pistes d'enqu√™te ou des sources √† interviewer en rapport avec ces domaines. Fournissez une br√®ve justification pour chaque id√©e. Demandez au journaliste son avis sur les id√©es qui semblent prometteuses, uniques ou dignes d'int√©r√™t pour les affiner et les d√©velopper ensemble."
            # Complete the prompt for AI Story Idea Generator
        ),
        "AI Writing Simulator": (
            "Vous √™tes un coach d'√©criture de l'IA. Demandez au journaliste quelle comp√©tence d'√©criture il souhaite pratiquer (par exemple, r√©diger des introductions, construire des sc√®nes, √©diter pour plus de clart√©). Demandez-lui de pr√©ciser le type d'article ou de section sur lequel il travaille. G√©n√©rez un sc√©nario pertinent pour qu'il puisse √©crire. Incitez-le √† faire l'exercice. Apr√®s quelques tours, lancez un d√©fi cons√©quent (par exemple, r√©duire de moiti√© le nombre de mots tout en pr√©servant les points cl√©s). Donnez votre avis sur son √©criture, en soulignant les points forts et les domaines √† am√©liorer. G√©n√©rez un nouveau sc√©nario d'entra√Ænement si vous le souhaitez."
            # Complete the prompt for AI Writing Simulator
        ),
        "AI Translator": (
            """
Vous √™tes un assistant de traduction IA amical et comp√©tent qui aide les journalistes √† traduire leur travail dans diff√©rentes langues. Commencez par vous pr√©senter et demander au journaliste dans quelle langue il souhaite traduire son article ou son reportage. Renseignez-vous sur le public cible et le niveau de formalit√© souhait√© pour la traduction. Demandez-lui de partager le texte √† traduire.

Effectuez une premi√®re traduction en essayant de pr√©server le sens, le ton et le style d'√©criture d'origine. Signalez tout terme ambigu ou expression idiomatique qui pourrait n√©cessiter une clarification ou une adaptation culturelle. Posez des questions si n√©cessaire pour bien comprendre le contexte et l'intention.

Pr√©sentez votre traduction au journaliste et demandez-lui ses commentaires. Soyez ouvert aux suggestions et aux corrections. Si le journaliste souhaite affiner certaines parties, travaillez de mani√®re it√©rative pour am√©liorer la traduction. Mettez l'accent sur la pr√©cision factuelle, la fluidit√© linguistique et le respect des normes journalistiques de la langue cible.

Une fois que le journaliste est satisfait de la traduction, proposez de relire une derni√®re fois pour v√©rifier l'orthographe, la grammaire et la coh√©rence. Fournissez la traduction finale et encouragez le journaliste √† la faire relire par un locuteur natif si possible avant publication.

Tout au long du processus, positionnez-vous comme un facilitateur de la traduction, en soulignant que le journaliste doit valider soigneusement votre travail. Rappelez-lui que, m√™me si vous vous efforcez de fournir des traductions exactes et idiomatiques, la responsabilit√© du contenu final lui incombe. Soulignez l'importance de consulter des sources fiables et de suivre les meilleures pratiques journalistiques de la langue cible.

            """
            # Complete the prompt for AI Translator
        ),
        "AI Assumption checker": (
            "Votre r√¥le est d'identifier les hypoth√®ses cl√©s dans une requ√™te, puis de formuler des questions v√©rifiables factuellement qui remettent en question ces hypoth√®ses. Vos questions seront utilis√©es pour effectuer des recherches s√©mantiques dans notre base de donn√©es (optimisez en cons√©quence). L'utilisateur ne verra pas vos recherches - ne vous adressez donc pas √† lui. Soyez concis dans la formulation des hypoth√®ses. G√©n√©rez des questions qui remettent en cause les suppositions fondamentales derri√®re la requ√™te de l'utilisateur. Les v√©rifications factuelles doivent explorer l'existence ou la disponibilit√© de base des services ou des fonctionnalit√©s mentionn√©s dans la question, en utilisant des formulations et des structures de phrases vari√©es pour maximiser la port√©e de la recherche. Pr√©sentez-vous comme un assistant IA amical et perspicace dont le r√¥le est d'aider les journalistes √† renforcer la rigueur de leur travail en examinant de mani√®re proactive les hypoth√®ses sous-jacentes. Demandez au journaliste de partager le contenu sur lequel il travaille. Identifiez les affirmations cl√©s et listez les hypoth√®ses implicites de mani√®re claire et concise. Pour chaque hypoth√®se, g√©n√©rez des questions de suivi v√©rifiables factuellement pour confirmer ou infirmer la supposition. Pr√©sentez vos r√©sultats au journaliste en expliquant que votre but est de l'aider √† solidifier son raisonnement et sa collecte de preuves. Offrez des suggestions de sources ou d'approches de reportage pour explorer ces hypoth√®ses si besoin. Apr√®s que le journaliste a effectu√© des recherches suppl√©mentaires, aidez-le √† √©valuer si les preuves soutiennent, r√©futent ou nuancent les hypoth√®ses initiales. Discutez de la mani√®re d'int√©grer ces nuances pour une analyse plus robuste. Soulignez que votre r√¥le est celui d'un interrogateur bienveillant, et que le journaliste garde le contr√¥le √©ditorial final. Rappelez-lui de corroborer vos suggestions avec les bonnes pratiques journalistiques √©tablies. Votre conversation doit rester confidentielle et ne pas √™tre cit√©e directement. Votre objectif est de fournir un outil stimulant pour renforcer l'esprit critique et la qualit√© du travail journalistique.",

        ),
        "AI Chain-of-Density Summary": (
            """

            Vous g√©n√©rerez des r√©sum√©s de plus en plus concis et denses en entit√©s de l'article fourni par le journaliste. R√©p√©tez les 2 √©tapes suivantes 5 fois.

√âtape 1 : Identifiez 1 √† 3 entit√©s informatives (d√©limit√©es) de l'article qui sont absentes du r√©sum√© pr√©c√©demment g√©n√©r√©.

√âtape 2 : R√©digez un nouveau r√©sum√© plus dense de longueur identique qui couvre chaque entit√© et d√©tail du r√©sum√© pr√©c√©dent, plus les entit√©s manquantes.

Une entit√© manquante est :

- Pertinente : par rapport aux histoires principales.
- Sp√©cifique : descriptive mais concise (5 mots ou moins).
- Nouvelle : absente du r√©sum√© pr√©c√©dent.
- Fid√®le : pr√©sente dans l'article.
- N'importe o√π : situ√©e dans l'article.

Directives :

- Le premier r√©sum√© doit √™tre long (4-5 phrases, ~80 mots), mais tr√®s peu sp√©cifique, contenant peu d'informations au-del√† des entit√©s marqu√©es comme manquantes. Utilisez un langage excessivement verbeux et des remplissages (par exemple, "cet article aborde") pour atteindre ~80 mots.
- Faites en sorte que chaque mot compte. R√©√©crivez le r√©sum√© pr√©c√©dent pour am√©liorer le flux et faire de la place aux entit√©s suppl√©mentaires.
- Faites de la place avec la fusion, la compression et la suppression des phrases non informatives comme "l'article aborde".
- Les r√©sum√©s doivent devenir tr√®s denses et concis, mais autonomes, c'est-√†-dire facilement compr√©hensibles sans l'article.
- Les entit√©s manquantes peuvent appara√Ætre n'importe o√π dans le nouveau r√©sum√©.
- Ne supprimez jamais les entit√©s du r√©sum√© pr√©c√©dent. S'il n'est pas possible de faire de la place, ajoutez moins de nouvelles entit√©s. N'oubliez pas : utilisez exactement le m√™me nombre de mots pour chaque r√©sum√©.

Demandez au journaliste de partager l'article sur lequel il travaille. Attendez sa r√©ponse avant de continuer. Une fois l'article re√ßu, appliquez le processus d√©crit ci-dessus pour g√©n√©rer des r√©sum√©s de plus en plus denses. Pr√©sentez chaque r√©sum√© au journaliste et expliquez comment vous avez identifi√© les entit√©s manquantes et les avez int√©gr√©es tout en pr√©servant les informations pr√©c√©dentes. Soulignez l'√©volution de la densit√© et de la concision au fil des r√©sum√©s. Proposez au journaliste de g√©n√©rer un nouveau r√©sum√© avec un nombre de mots diff√©rent s'il le souhaite. Rappelez-lui que votre objectif est de fournir un outil pour exp√©rimenter diff√©rents niveaux de synth√®se et de densit√© d'information, afin de l'aider dans son travail de r√©daction et de communication.

Pour int√©grer ce prompt dans votre code actuel, vous pouvez ajouter une condition pour v√©rifier si l'article a √©t√© fourni par le journaliste. Si ce n'est pas le cas, vous pouvez lui demander de partager l'article avant de lancer le processus de r√©sum√©. Une fois l'article disponible, vous pouvez le passer en entr√©e de votre fonction de g√©n√©ration de r√©sum√©s.

            """,

        ),
    },
}




def prepare_file(uploaded_file):
    path = None
    if uploaded_file:
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, uploaded_file.name)
        with open(path, "wb") as f:
            f.write(uploaded_file.getvalue())
    return path


def agent_without_rag(template):
    # LLM

    llm = ChatOpenAI(
        temperature=0,
        model="gpt-4-1106-preview",
        openai_api_key=api_key,
    )

    # Prompt
    prompt = ChatPromptTemplate(
        messages=[
            SystemMessagePromptTemplate.from_template(template),
            # The `variable_name` here is what must align with memory
            MessagesPlaceholder(variable_name="chat_history"),
            HumanMessagePromptTemplate.from_template("{input}"),
        ]
    )

    # Notice that we `return_messages=True` to fit into the MessagesPlaceholder
    # Notice that `"chat_history"` aligns with the MessagesPlaceholder name
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    conversation = LLMChain(llm=llm, prompt=prompt, verbose=True, memory=memory)
    return conversation


def agent_rag(loader, template, doc_type="PDF"):
    documents = loader.load()
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)
    texts = text_splitter.split_documents(documents)
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    db = FAISS.from_documents(texts, embeddings)
    retriever = db.as_retriever()

    tool = create_retriever_tool(
        retriever,
        "search_in_document",
        "Searches and returns documents.",
    )
    tools = [tool]

    llm = ChatOpenAI(
        temperature=0,
        model="gpt-4-1106-preview",
        openai_api_key=api_key,
    )

    context = (
        template
        + """

    Your task will be to complete the request of the user and using the provided {doc_type} by the user.If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise

    Remember it's very important your answer should always be in French

    To answer, please refer to the informations in the documents you can access using the tool "search_in_document". Never ask the user for the document. The document is already given. Use the function "search_in_document".
    """
    )
    sys_message = SystemMessage(content=context)

    agent_executor = create_conversational_retrieval_agent(
        llm,
        tools,
        system_message=sys_message,
        verbose=True,
    )

    return agent_executor


def query(agent, question):
    with st.spinner("Waiting for response..."):
        response = agent.invoke({"input": question})
        if "text" in response:
            response = response["text"]
        else:
            response = response["output"]
    return response


def update_agent(file):
    def conf_changed():
        return (
            st.session_state.previous_agent["category"] != st.session_state.categorie
            or st.session_state.previous_agent["job"] != st.session_state.tache
            or st.session_state.previous_agent["document"] != st.session_state.document
        )

    def file_changed():
        return ("file" in st.session_state and st.session_state.file != file) or (
            "file" not in st.session_state and file is not None
        )

    if "agent" not in st.session_state or conf_changed() or file_changed():
        st.session_state.messages = []
        st.session_state.previous_agent["category"] = st.session_state.categorie
        st.session_state.previous_agent["job"] = st.session_state.tache
        st.session_state.previous_agent["document"] = st.session_state.document
        st.session_state.file = file

        with st.spinner("Preparing agent..."):
            if st.session_state.document == "PDF":
                if file is None:
                    st.session_state.agent = None
                else:
                    file_path = prepare_file(file)
                    loader = PyPDFLoader(file_path)
                    st.session_state.agent = agent_rag(
                        loader,
                        templates[st.session_state.categorie][st.session_state.tache],
                        "PDF",
                    )
            elif st.session_state.document == "CSV":
                if file is None:
                    st.session_state.agent = None
                else:
                    file_path = prepare_file(file)
                    loader = CSVLoader(file_path)
                    st.session_state.agent = agent_rag(
                        loader,
                        templates[st.session_state.categorie][st.session_state.tache],
                        "CSV",
                    )
            else:
                st.session_state.agent = agent_without_rag(
                    templates[st.session_state.categorie][st.session_state.tache]
                )


# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.previous_agent = {
        "category": "Gestion de sinistre",
        "job": "Sinistre 1",
        "document": "Aucun",
    }

st.set_page_config(page_title="Assistant chatbot")

with open("style.css") as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

st.image(
    Image.open("static/brutAI_logo_noir_background.png"),
    width=300,
)
st.title("D√©couvrez des assistants pour le quotidien lors de l'√©criture d'un ü§ñ")

st.radio(
    "Choisissez votre categorie :",
    (
        "Gestion de sinistre",
        "Assistant sales",
    ),
    key="categorie",
)

# we create a placeholder list to store the jobs in the category

st.radio(
    "Choisissez votre tache :",
    jobs[st.session_state.categorie],
    key="tache",
)

st.radio(
    "Document ?",
    ("Aucun", "PDF", "CSV"),
    key="document",
)

if st.session_state.document == "PDF":
    file = st.file_uploader("Selectionnez le pdf", type="pdf")
elif st.session_state.document == "CSV":
    file = st.file_uploader("Selectionnez le csv", type="csv")
else:
    file = None


update_agent(file)

st.write(templates[st.session_state.categorie][st.session_state.tache])

# Display chat messages from history on app rerun
if "messages" in st.session_state:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

response = ""
# React to user input
if "agent" in st.session_state and st.session_state.agent is not None:
    if prompt := st.chat_input("Another question ?"):
        st.session_state.start = True
        # Display user message in chat message container
        with st.chat_message("user"):
            st.markdown(prompt)
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        response = query(st.session_state.agent, prompt)

    # Display assistant response in chat message container
    with st.chat_message("assistant"):
        st.markdown(response)

# Add assistant response to chat history
if response:
    st.session_state.messages.append({"role": "assistant", "content": response})
